{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.paulgraham.com/greatwork.html', 'https://www.paulgraham.com/kids.html', 'https://www.paulgraham.com/selfindulgence.html', 'https://www.paulgraham.com/field.html', 'https://www.paulgraham.com/goodwriting.html', 'https://www.paulgraham.com/do.html', 'https://www.paulgraham.com/woke.html', 'https://www.paulgraham.com/writes.html', 'https://www.paulgraham.com/when.html', 'https://www.paulgraham.com/foundermode.html', 'https://www.paulgraham.com/persistence.html', 'https://www.paulgraham.com/reddits.html', 'https://www.paulgraham.com/google.html', 'https://www.paulgraham.com/best.html', 'https://www.paulgraham.com/superlinear.html', 'https://www.paulgraham.com/getideas.html', 'https://www.paulgraham.com/read.html', 'https://www.paulgraham.com/want.html', 'https://www.paulgraham.com/alien.html', 'https://www.paulgraham.com/users.html', 'https://www.paulgraham.com/heresy.html', 'https://www.paulgraham.com/words.html', 'https://www.paulgraham.com/goodtaste.html', 'https://www.paulgraham.com/smart.html', 'https://www.paulgraham.com/weird.html', 'https://www.paulgraham.com/hwh.html', 'https://www.paulgraham.com/own.html', 'https://www.paulgraham.com/fn.html', 'https://www.paulgraham.com/newideas.html', 'https://www.paulgraham.com/nft.html', 'https://www.paulgraham.com/real.html', 'https://www.paulgraham.com/richnow.html', 'https://www.paulgraham.com/simply.html', 'https://www.paulgraham.com/donate.html', 'https://www.paulgraham.com/worked.html', 'https://www.paulgraham.com/earnest.html', 'https://www.paulgraham.com/ace.html', 'https://www.paulgraham.com/airbnbs.html', 'https://www.paulgraham.com/think.html', 'https://www.paulgraham.com/early.html', 'https://www.paulgraham.com/wtax.html', 'https://www.paulgraham.com/conformism.html', 'https://www.paulgraham.com/orth.html', 'https://www.paulgraham.com/cred.html', 'https://www.paulgraham.com/useful.html', 'https://www.paulgraham.com/noob.html', 'https://www.paulgraham.com/fh.html', 'https://www.paulgraham.com/mod.html', 'https://www.paulgraham.com/fp.html', 'https://www.paulgraham.com/lesson.html', 'https://www.paulgraham.com/nov.html', 'https://www.paulgraham.com/genius.html', 'https://www.paulgraham.com/sun.html', 'https://www.paulgraham.com/pow.html', 'https://www.paulgraham.com/disc.html', 'https://www.paulgraham.com/pgh.html', 'https://www.paulgraham.com/vb.html', 'https://www.paulgraham.com/ineq.html', 'https://www.paulgraham.com/re.html', 'https://www.paulgraham.com/jessica.html', 'https://www.paulgraham.com/bias.html', 'https://www.paulgraham.com/talk.html', 'https://www.paulgraham.com/aord.html', 'https://www.paulgraham.com/safe.html', 'https://www.paulgraham.com/name.html', 'https://www.paulgraham.com/altair.html', 'https://www.paulgraham.com/ronco.html', 'https://www.paulgraham.com/work.html', 'https://www.paulgraham.com/corpdev.html', 'https://www.paulgraham.com/95.html', 'https://www.paulgraham.com/ecw.html', 'https://www.paulgraham.com/know.html', 'https://www.paulgraham.com/pinch.html', 'https://www.paulgraham.com/mean.html', 'https://www.paulgraham.com/before.html', 'https://www.paulgraham.com/fr.html', 'https://www.paulgraham.com/herd.html', 'https://www.paulgraham.com/convince.html', 'https://www.paulgraham.com/ds.html', 'https://www.paulgraham.com/invtrend.html', 'https://www.paulgraham.com/startupideas.html', 'https://www.paulgraham.com/hw.html', 'https://www.paulgraham.com/growth.html', 'https://www.paulgraham.com/swan.html', 'https://www.paulgraham.com/todo.html', 'https://www.paulgraham.com/speak.html', 'https://www.paulgraham.com/ycstart.html', 'https://www.paulgraham.com/property.html', 'https://www.paulgraham.com/ambitious.html', 'https://www.paulgraham.com/word.html', 'https://www.paulgraham.com/schlep.html', 'https://www.paulgraham.com/vw.html', 'https://www.paulgraham.com/hubs.html', 'https://www.paulgraham.com/patentpledge.html', 'https://www.paulgraham.com/airbnb.html', 'https://www.paulgraham.com/control.html', 'https://www.paulgraham.com/tablets.html', 'https://www.paulgraham.com/founders.html', 'https://www.paulgraham.com/superangels.html', 'https://www.paulgraham.com/seesv.html', 'https://www.paulgraham.com/hiresfund.html', 'https://www.paulgraham.com/yahoo.html', 'https://www.paulgraham.com/future.html', 'https://www.paulgraham.com/addiction.html', 'https://www.paulgraham.com/top.html', 'https://www.paulgraham.com/organic.html', 'https://www.paulgraham.com/apple.html', 'https://www.paulgraham.com/really.html', 'https://www.paulgraham.com/discover.html', 'https://www.paulgraham.com/publishing.html', 'https://www.paulgraham.com/nthings.html', 'https://www.paulgraham.com/determination.html', 'https://www.paulgraham.com/kate.html', 'https://www.paulgraham.com/segway.html', 'https://www.paulgraham.com/ramenprofitable.html', 'https://www.paulgraham.com/makersschedule.html', 'https://www.paulgraham.com/revolution.html', 'https://www.paulgraham.com/twitter.html', 'https://www.paulgraham.com/foundervisa.html', 'https://www.paulgraham.com/5founders.html', 'https://www.paulgraham.com/relres.html', 'https://www.paulgraham.com/angelinvesting.html', 'https://www.paulgraham.com/convergence.html', 'https://www.paulgraham.com/maybe.html', 'https://www.paulgraham.com/hackernews.html', 'https://www.paulgraham.com/13sentences.html', 'https://www.paulgraham.com/identity.html', 'https://www.paulgraham.com/credentials.html', 'https://www.paulgraham.com/divergence.html', 'https://www.paulgraham.com/highres.html', 'https://www.paulgraham.com/artistsship.html', 'https://www.paulgraham.com/badeconomy.html', 'https://www.paulgraham.com/fundraising.html', 'https://www.paulgraham.com/prcmc.html', 'https://www.paulgraham.com/cities.html', 'https://www.paulgraham.com/distraction.html', 'https://www.paulgraham.com/lies.html', 'https://www.paulgraham.com/good.html', 'https://www.paulgraham.com/googles.html', 'https://www.paulgraham.com/heroes.html', 'https://www.paulgraham.com/disagree.html', 'https://www.paulgraham.com/boss.html', 'https://www.paulgraham.com/ycombinator.html', 'https://www.paulgraham.com/trolls.html', 'https://www.paulgraham.com/newthings.html', 'https://www.paulgraham.com/startuphubs.html', 'https://www.paulgraham.com/webstartups.html', 'https://www.paulgraham.com/philosophy.html', 'https://www.paulgraham.com/colleges.html', 'https://www.paulgraham.com/die.html', 'https://www.paulgraham.com/head.html', 'https://www.paulgraham.com/stuff.html', 'https://www.paulgraham.com/equity.html', 'https://www.paulgraham.com/unions.html', 'https://www.paulgraham.com/guidetoinvestors.html', 'https://www.paulgraham.com/judgement.html', 'https://www.paulgraham.com/microsoft.html', 'https://www.paulgraham.com/notnot.html', 'https://www.paulgraham.com/wisdom.html', 'https://www.paulgraham.com/foundersatwork.html', 'https://www.paulgraham.com/goodart.html', 'https://www.paulgraham.com/startupmistakes.html', 'https://www.paulgraham.com/mit.html', 'https://www.paulgraham.com/investors.html', 'https://www.paulgraham.com/copy.html', 'https://www.paulgraham.com/island.html', 'https://www.paulgraham.com/marginal.html', 'https://www.paulgraham.com/america.html', 'https://www.paulgraham.com/siliconvalley.html', 'https://www.paulgraham.com/startuplessons.html', 'https://www.paulgraham.com/randomness.html', 'https://www.paulgraham.com/softwarepatents.html', 'https://www.paulgraham.com/6631327.html', 'https://www.paulgraham.com/whyyc.html', 'https://www.paulgraham.com/love.html', 'https://www.paulgraham.com/procrastination.html', 'https://www.paulgraham.com/web20.html', 'https://www.paulgraham.com/startupfunding.html', 'https://www.paulgraham.com/vcsqueeze.html', 'https://www.paulgraham.com/ideas.html', 'https://www.paulgraham.com/sfp.html', 'https://www.paulgraham.com/inequality.html', 'https://www.paulgraham.com/ladder.html', 'https://www.paulgraham.com/opensource.html', 'https://www.paulgraham.com/hiring.html', 'https://www.paulgraham.com/submarine.html', 'https://www.paulgraham.com/bronze.html', 'https://www.paulgraham.com/mac.html', 'https://www.paulgraham.com/writing44.html', 'https://www.paulgraham.com/college.html', 'https://www.paulgraham.com/venturecapital.html', 'https://www.paulgraham.com/start.html', 'https://www.paulgraham.com/hs.html', 'https://www.paulgraham.com/usa.html', 'https://www.paulgraham.com/charisma.html', 'https://www.paulgraham.com/polls.html', 'https://www.paulgraham.com/laundry.html', 'https://www.paulgraham.com/bubble.html', 'https://www.paulgraham.com/essay.html', 'https://www.paulgraham.com/pypar.html', 'https://www.paulgraham.com/gh.html', 'https://www.paulgraham.com/gap.html', 'https://www.paulgraham.com/wealth.html', 'https://www.paulgraham.com/gba.html', 'https://www.paulgraham.com/say.html', 'https://www.paulgraham.com/ffb.html', 'https://www.paulgraham.com/hp.html', 'https://www.paulgraham.com/iflisp.html', 'https://www.paulgraham.com/hundred.html', 'https://www.paulgraham.com/nerds.html', 'https://www.paulgraham.com/better.html', 'https://www.paulgraham.com/desres.html', 'https://www.paulgraham.com/spam.html', 'https://www.paulgraham.com/icad.html', 'https://www.paulgraham.com/power.html', 'https://www.paulgraham.com/fix.html', 'https://www.paulgraham.com/taste.html', 'https://www.paulgraham.com/noop.html', 'https://www.paulgraham.com/diff.html', 'https://www.paulgraham.com/road.html', 'https://www.paulgraham.com/rootsoflisp.html', 'https://www.paulgraham.com/langdes.html', 'https://www.paulgraham.com/popular.html', 'https://www.paulgraham.com/javacover.html', 'https://www.paulgraham.com/avg.html', 'https://www.paulgraham.com/lwba.html', 'https://www.paulgraham.com/progbot.html', 'https://www.paulgraham.com/prop62.html']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"links.txt\"\n",
    "\n",
    "base_url = \"https://www.paulgraham.com/\"\n",
    "\n",
    "with open(file_path) as f:\n",
    "    links = json.load(f)\n",
    "\n",
    "full_links = [base_url + link for link in links]\n",
    "\n",
    "print(full_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bytehead/projects/temp/rag/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"PG_essays\",\n",
    "    embedding_function=hf,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4161 chunks from 228 documents.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from datetime import datetime\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=full_links,\n",
    "    bs_kwargs=dict(parse_only=bs4.SoupStrainer([\"title\", \"body\"])),\n",
    ")\n",
    "try:\n",
    "    docs = loader.load()\n",
    "    for doc in docs:\n",
    "        doc.metadata[\"chunk_source\"] = \"web scraping\"\n",
    "        doc.metadata[\"processing_date\"] = str(datetime.now())\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    all_splits = text_splitter.split_documents(docs)\n",
    "    print(f\"Loaded {len(all_splits)} chunks from {len(docs)} documents.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading or processing documents: {e}\")\n",
    "\n",
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# Define prompt for question-answering\n",
    "# N.B. for non-US LangSmith endpoints, you may need to specify\n",
    "# api_url=\"https://api.smith.langchain.com\" in hub.pull.\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The primary reason startups fail is not making something users want. This fundamental mistake can stem from various factors, including having a single founder. Additionally, slow growth or excessive spending can lead to startups running out of funding.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"Why do startups fail?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=5)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Step 2: Execute the retrieval.\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "\n",
    "# Step 3: Generate a response using the retrieved content.\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks from Paul Graham's essays and are called AskPG. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding a node to a graph that has already been compiled. This will not be reflected in the compiled graph.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Node `query_or_respond` already present.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01muuid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m uuid4\n\u001b[32m      6\u001b[39m memory = MemorySaver()\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mgraph_builder\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_or_respond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m graph_builder.add_node(tools)\n\u001b[32m     10\u001b[39m graph_builder.add_node(generate)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/temp/rag/.venv/lib/python3.13/site-packages/langgraph/graph/state.py:456\u001b[39m, in \u001b[36mStateGraph.add_node\u001b[39m\u001b[34m(self, node, action, defer, metadata, input_schema, retry_policy, cache_policy, destinations, **kwargs)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nodes:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNode `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` already present.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m node == END \u001b[38;5;129;01mor\u001b[39;00m node == START:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNode `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` is reserved.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Node `query_or_respond` already present."
     ]
    }
   ],
   "source": [
    "from langgraph.graph import END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from uuid import uuid4\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid4())}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "How to make sure my startup wont fail?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "To increase your startup's chances of success, consider these key points:\n",
      "\n",
      "1.  **Iterate on your ideas:** Don't treat your initial idea as set in stone. Many valuable ideas will emerge during the implementation process.\n",
      "2.  **Understand your users deeply:** Focus on truly understanding what your users lack and how you can improve their lives. This understanding is crucial for creating something they genuinely need.\n",
      "3.  **Aim for love, not just acceptance:** It's better to have a small group of users who absolutely love your product than a large group who are indifferent. This strong initial engagement can drive further growth.\n",
      "4.  **Do things that don't scale:** Startups often need a \"manual push\" to get going. This might involve actively recruiting users one-by-one rather than waiting for them to find you. Founders need to be proactive in making their startup take off.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"How to make sure my startup wont fail?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
